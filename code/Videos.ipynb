{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys, math\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_path = os.path.join(os.path.dirname(os.getcwd()), 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['haarcascade_frontalface_default.xml',\n",
       " 'butterfly.jpg',\n",
       " 'fruits.jpg',\n",
       " 'bw_image_butterfy.png',\n",
       " 'processed_video.avi',\n",
       " 'bw_image_butterfy.tiff',\n",
       " 'Megamind_bugy.avi']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video(video_path: os.path = 0, process_frame = lambda x: x, save_processed_video=False):\n",
    "    video_stream = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if save_processed_video:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "        video_writer = cv2.VideoWriter(os.path.join(data_dir_path, 'processed_video.avi'), fourcc, video_stream.get(5), (int(video_stream.get(3)), int(video_stream.get(4))))\n",
    "    \n",
    "    print(video_stream.isOpened())\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "\n",
    "            ret, frame = video_stream.read()\n",
    "\n",
    "            processed_frame = process_frame(frame)\n",
    "            \n",
    "            if save_processed_video:\n",
    "                video_writer.write(processed_frame)\n",
    "\n",
    "            horizontal_show = np.concatenate((frame, processed_frame), axis=1)\n",
    "\n",
    "            cv2.imshow('processed_frame', horizontal_show)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    finally:\n",
    "        video_stream.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "read_video(process_frame=convert_image_to_BW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_to_BW(image):\n",
    "    bw_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.cvtColor(bw_img, cv2.COLOR_GRAY2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDetection(object):\n",
    "    \n",
    "    def __init__(self, haar_cascade_file_path):\n",
    "        self.hcfp = haar_cascade_file_path\n",
    "        self._load_classifier()\n",
    "    \n",
    "    def _load_classifier(self):\n",
    "        self.classifier = cv2.CascadeClassifier(self.hcfp)\n",
    "        \n",
    "    def detect_faces(self, image):\n",
    "        copied_image = copy.deepcopy(image)\n",
    "        gray = convert_image_to_BW(image)\n",
    "        \n",
    "        faces = self.classifier.detectMultiScale(gray, 1.3, 5)\n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            tagged_image = cv2.rectangle(copied_image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        \n",
    "        return copied_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_obj = FaceDetection(os.path.join(data_dir_path, 'haarcascade_frontalface_default.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "read_video(process_frame=fd_obj.detect_faces, save_processed_video=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
